自我介绍：

>面试官您好，我叫邵龙凌，我本科 就读于安徽师范大学的软件工程专业，目前是应技大电子信息专业的硕士研究生。目前希望能够找到一份Java后端开发的实习。
>
>我的技术栈主要包括Java、MySQL、SpringBoot、MyBatis、Redis，并且对数据结构与算法有一定的掌握。
>
>从今年6月到9月份，我在上海阳狮集团实习，岗位是Java后端开发。实习期间，我参与了百威供应商管理系统2.0的开发，这是个小型的单体项目，让我巩固了很多Java基础、框架使用方面的知识。
>
>在项目开发方面，我学习了一个校园商城项目，我在这个项目中通过Redis优化了商铺信息缓存，提高了查询效率。然后设计了高并发下的点赞系统，大幅减轻了数据库压力。
>
>我期待未来能够将我所学的技术和经验运用到更多实际项目中，持续提升我的开发能力，谢谢！

使用分布式锁实现商品的秒杀，不仅解决了商品超卖的问题，并且保证了一人只能购买一单。

```
	我在实现商品超卖的问题时，使用的是乐观锁，并且直接使用库存数量作为CAS中的版本号来实现，在每一次扣减库存的时候，sql语句判断库存是否等于之前查询时的库存，
如果不相等，说明版本号不一致，就更新失败。但是这样如果有100个人同时抢票，最后可能卖的票只有10张，所以进一步修改判断操作，在扣减库存的时候，判断库存是否>0。
这样就解决了超卖问题。
	而一人一单问题一开始是在单体架构上实现的，防止黄牛用一个id抢多个票，使用可synchronized锁住了用户id，保证同一个用户只能购票一次，这里有一个细节，锁住
用户id不能直接在synchronized中写userid，而是要写userId.intern()。因为直接锁userId，不同线程new出的String对象是处于JVM的堆中，即便他们在值上是
相等的，但是对象是不同的，因此需要使用intern方法，去拿到常量池中的userId，这样才能保证锁住的userId是同一个对象。这样就实现了一人一单的问题。
	后来，如果项目需要扩容，要用多个服务器提高可用性。那么在JVM层面的锁就失效了，因为不同服务器的JVM是独立的。这个时候就需要一个中间件来统一管理，我就用到
了redis作为分布式锁。在redis中有一个setnx命令，就是当key不存在的时候，才会去创建记录。因此我将UserId作为key，在tryLock方法中使用setnx命令，如果
setnx成功，说明获取锁成功，反之失败。这样就解决了分布式架构上一人一单的问题了。
```

使用redis实现全局唯一id生成器？

```ne
	用户抢购时，会生成订单到订单表中，如果订单表使用数据库自增id会产生问题。首先规律太明显了，竞争对手很容易就能知道我们的销售量，然后如果表足够大以后需要进
行分表，虽然表从物理上分开了，但是逻辑上还是一张表，就不好使用自增id了。
	所以我使用Redis作为全局id生成器，因为他能同时做到快、自增、安全。
	具体使用了时间戳+序列号的拼接，然后redis做increment操作，最终就能返回一个全局唯一的id。
```

使用Redis实现分布式Session，解决集群间登录态同步问题

```ne
	这个项目一开始使用Session来在服务端存储用户的token，但是多台tomcat并不共享session的存储空间，当请求切换到不同tomcat服务时，数据就会丢失。
因此要采用redis来统一管理用户的token，这里使用了Redis中String的数据结构，如果直接将用户的电话号码作为key，这种敏感信息传来传去肯定是不合适的，
所以最终使用了随机字符串作为key，这样就使用Redis实现了分布式Session。
	但是集群间的登录态同步问题没有解决。如果一个用户访问那些不需要拦截的页面，就是访问首页，商铺之类的页面，是不会去刷新token有效期的。因此我就添加了
一个拦截器，在第一个拦截器中拦截所有的路径，将用户存入ThreadLocal中，第二个拦截器才去拦截需要登录的界面，去ThreadLocal中取数据，如果用户不存在就拦截。
于是这样就解决了集群间登录态的同步问题。
```

点赞？

```ne
	key是博客的id，value是用户id。score不是点赞数而是根据时间来排序，然后会在博客页面显示点赞用户的头像。点赞就是将用户和时间添加到redis中，取消点赞
就是删除zset中的记录。
```



---

**视频续播：**

​	这个项目中的课程是以录播视频为主，为了提高用户的学习体验，就需要实现视频的断点续播功能。首先要控制误差在30秒以内，而且用户停止播放后，即便使用另一个设备去播放，也能从上一次结束的地方开始播放。

​	首先，要做到切换设备之后还能续播，用户的播放进度必须保存在服务端，而不是客户端。

​	其次，用户突然断开或者切换设备，续播的时间误差不能超过30秒，那么记录频率就需要比较高。前端是每隔15秒发送一次心跳请求，提交最近的播放进度，记录到服务端，这样用户下一次续播时会直接读取服务端的播放进度，这样就可以将时间误差控制在15秒左右。

​	当然，提交播放记录最终肯定是要保存到数据库中的，因为15秒发送一次请求，在用户量大的情况下，会对数据库造成巨大压力。因此我采用了合并写请求的方案，当用户提交播放进度时会**先缓存再Redis中，后续再持久化到数据库**当中。由于播放进度会不断覆盖，因此只保留最后一次就可以了。这样就能够大大减少对数据库的访问次数和访问频率了。

​	先缓存到redis，再持久化到数据库，什么时候持久化也是一个问题，因为我不知道什么时候用户真正停止了播放。这个时候就要抓住业务的特点，只要用户在播放视频，redis中的记录就一直会变化，一旦redis中记录不变了，说明用户就暂停或者退出了播放。这个时候就需要使用延迟队列，在每一次前端提交进度时，都使用延迟队列保存。在20秒后执行任务，看队列中的进度是否和redis中的进度一致。不一致说明用户还在观看，不用处理。一致了就可以将进度持久化到数据中了。

---

**点赞业务**

​	首先在设计之初，我分析了点赞业务的要求。首先在整个项目中需要用到点赞的业务不止一个，为了防止点赞业务和其他业务耦合，需要将点赞业务单独做成一个微服务，让他们通过RabbitMq来实现通信。其次，点赞业务可能会有较高的并发，因此需要考虑到高并发写库压力的问题。

​	为了减少数据库压力，我利用Redis来保存点赞记录、点赞数量信息，然后利用**定时任务**定期将点赞数量同步给业务方，持久化到数据库中。

**具体数据结构：**

​	使用到了两种数据结构，set和zset。

​	**set**：key：业务id，value：点赞用户id。SADD，srem,sismember,scard。redis的set结构会在头信息中保存元素数量，因此scard的时间复杂度是O(1)的。

​	但是这里存在一个问题，判断当前用户有没有对某些业务点赞。会传来多个业务id的集合。而sismember只能一次判断一个业务的点赞状态，要判断多个业务点赞状态的话，与Redis多次交互是不合适的，所以我采用了Pipeline管道方式，这样就可以一次请求实现多个业务点赞状态的判断了。

​	**zset**：zset不是用来实现点赞业务的，点赞只靠set就可以实现了，但是这里有一个问题，我们要定期将点赞总数通过MQ同步给业务方并持久化到数据库。如果只用set的话，**无法知道哪些业务点赞数发生了变化**，需要同步到业务方。

​		因此我们又添加了zset结构用来记录点赞数变化的业务以及对应的点赞总数。可以理解为一个**待持久化的点赞任务队列**。

​		每当业务被点赞，除了要缓存点赞记录，还要把**业务id及点赞总数写入zset**，这样**定时任务开启**时，只需要从zset中**获取并移除数据**，然后发送mq给业务方，并持久化到数据库即可。当然zset方案也不是完全没有问题的，毕竟他的底层结构是跳表，对内存有一定的占用。但是考虑到每次更新完都会删除数据，所以zset中的数据会始终保持在一个较低级别。

​	**为什么不用List？**

​	假设定时任务每隔2分钟执行一次，一个业务如果在2分钟内多次被点赞，就会多次向List中添加同一个业务及对应的点赞总数，数据库也要持久化多次。这肯定是多余的，因为只有最后一次是有效的。ZSET因为member的唯一性，即便多次添加，最终也只会持久化一次。

​	**为什么不能用set？**

​		

---

**排行榜**

问：排行榜怎么实现的？说说排行榜

答：

​	排行榜功能分为两个部分，一个是当前赛季排行榜，一个是历史赛季排行榜。

​	在本项目中，一个月是一个赛季，这样学员就有动力去学习，有了赛季的概念，因此也就有了当前赛季榜单和历史榜单的区分，实现的思路也是不一样的。

**当前赛季榜单：**

​	采用了Redis的SortedSet来实现，member是用户id，score是当月积分总值。每当用户产生积分行为的时候，就会更新score值，因为sortedSet本身就是自动排序的，因此也就自动实现了榜单，方便并且高效。

​	在用户量达到百万级别的情况下，因为底层采用了跳表的机制，效率也是非常高的。如果用户量规模达到数千万以上，就可以采用分治的思想，将用户数据按照积分范围划分为多个桶。

**历史赛季榜单：**

​	历史赛季榜单需要保存到数据库。不过由于数据过多，所以需要对数据做水平拆分。我的思路是按照赛季来进行拆分，也就是每一个赛季榜单是一个单独的表。这样有几个好处：

* 拆分数据时比较自然，不需要做额外的处理
* 查询数据往往都是按照赛季来查询，这样就只需要查询一张表，不存在跨表查询的问题

因此我们就不需要分库分表的插件了，直接在业务层利用MP实现动态表名，动态插入简单又高效。

​	此外，我使用定时任务在每月初生成上个赛季的榜单，然后再用一个定时任务去读取Redis中的榜单，持久化到数据库。最后再使用一个定时任务清理Redis中的历史数据。

​	这里三个任务是有关联的，之所以分成了三个定时任务，是为了避免任务耦合，这样在部分任务失败的时候就可以单独进行重试，不需要从头重试。

**定时任务：**

​	我使用的定时任务框架式xxl-job，他自带任务的分片广播机制，每一个任务执行器都能通过API得到自己的编号，总数量。在做榜单数据批处理的时候，采用分页查询的方式。比如执行器数量是2个，那么1号执行器就处理编号为奇数的页，2号执行器就处理编号为偶数的页。这样就可以确保对于数据处理的不重不漏。

​	最后为了确保任务的执行顺序，使用到了xxl-job中的子任务功能，比如有任务ABC，将B设置为A的子任务，C设置为B的子任务，只要触发了A任务，就可以一次执行ABC任务了！



--

# 商城

如何保证支付服务和交易服务之间订单状态一致？

答：首先，支付服务会在用户支付成功以后利用MQ异步通知交易服务，完成订单状态同步。其次，为了保证MQ消息的可靠性，我们采用了生产者确认、消费者确认、消费者失败重试等策略，确保了消息传递和处理的可靠性。同时也开启了MQ持久化，避免服务器宕机导致数据丢失。最后，我在交易服务更新订单状态时做了业务判断，避免消息重复消费导致订单状态异常。



如果交易服务消息处理失败，有没有什么兜底方案？

![Default Canvas1(3)](https://s2.loli.net/2024/09/13/OdRm9iHPheCqnjL.png)
